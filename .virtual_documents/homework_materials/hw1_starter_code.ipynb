#@title Imports and Initialization
# %pip install datasets
# %pip install textwrap
# %pip install openai
# %pip install scipy
# %pip install matplotlib

import collections
from abc import ABC
import datasets
import json
import openai
import numpy as np
from scipy.special import softmax
import textwrap
import matplotlib.pyplot as plt
from IPython.display import clear_output

OPENAI_SECRET_KEY = None

clear_output()





if OPENAI_SECRET_KEY is None:
  print("Please paste your OpenAI API key here:")
  OPENAI_SECRET_KEY = input().strip()
openai.api_key = OPENAI_SECRET_KEY
clear_output()

class OpenAIEngine():
  def __init__(self, model_name):
    self.model_name = model_name

  def score(self, text):
    """Tokenizes and scores a piece of text.

    This only works for the OpenAI models which support the legacy `Completion`
    API.

    The score is log-likelihood. A higher score means a token was more
    likely according to the model.

    Returns a list of tokens and a list of scores.
    """
    response = openai.Completion.create(
        engine=self.model_name,
        prompt=text,
        max_tokens=0,
        logprobs=1,
        echo=True)

    tokens = response["choices"][0]["logprobs"]["tokens"]
    logprobs = response["choices"][0]["logprobs"]["token_logprobs"]
    if logprobs and logprobs[0] is None:
      # GPT-3 API does not return logprob of the first token
      logprobs[0] = 0.0
    return tokens, logprobs

  def perplexity(self, text):
    """Compute the perplexity of the provided text."""
    completion = openai.Completion.create(
        model=self.model_name,
        prompt=text,
        logprobs=0,
        max_tokens=0,
        temperature=1.0,
        echo=True)
    token_logprobs = completion['choices'][0]['logprobs']['token_logprobs']
    nll = np.mean([i for i in token_logprobs if i is not None])
    ppl = np.exp(-nll)
    return ppl

  def generate(self,
               prompt,
               top_p=1.0,
               num_tokens=32,
               num_samples=1,
               frequency_penalty=0.0,
              presence_penalty=0.0):
    """Generates text given the provided prompt text.

    This only works for the OpenAI models which support the legacy `Completion`
    API.

    If num_samples is 1, a single generated string is returned.
    If num_samples > 1, a list of num_samples generated strings is returned.
    """
    response = openai.Completion.create(
      engine=self.model_name,
      prompt=prompt,
      temperature=1.0,
      max_tokens=num_tokens,
      top_p=top_p,
      n=num_samples,
      frequency_penalty=frequency_penalty,
      presence_penalty=presence_penalty,
      logprobs=1,
    )
    outputs = [r["text"] for r in response["choices"]]
    return outputs[0] if num_samples == 1 else outputs


  def chat_generate(self,
                    previous_messages,
                    top_p=1.0,
                    num_tokens=32,
                    num_samples=1,
                    frequency_penalty=0.0,
                    presence_penalty=0.0):
    response = openai.ChatCompletion.create(
      model=self.model_name,
      messages=previous_messages,
      temperature=1.0,
      max_tokens=num_tokens,
      top_p=top_p,
      frequency_penalty=frequency_penalty,
      presence_penalty=presence_penalty,
      n=num_samples,
    )
    return response








MODEL_NAME = "davinci-002"
engine = OpenAIEngine(MODEL_NAME)


number_map = {
    "one": 1,
    "two": 2,
    "three": 3,
    "four": 4,
    "five": 5,
    "six": 6,
    "seven": 7,
    "eight": 8,
    "nine": 9,
    "ten": 10,
    "eleven": 11,
    "twelve": 12,
    "thirteen": 13,
    "fourteen": 14,
    "fifteen": 15,
    "sixteen": 16,
    "seventeen": 17,
    "eighteen": 18,
    "nineteen": 19,
    "twenty": 20
}


# prompt = "Let's roll a D20. The die shows the number"
# prompt = "Let's roll a D20, which randomly get a number from 1 to 20, the number is?"
# prompt = "Let's roll a D20, which number does this die show?"
prompt = "Let's roll a D20, the number is"
rolls = engine.generate(prompt, num_tokens=2, num_samples=128, top_p=0.2)
# rolls = engine.generate(prompt, num_samples=128, top_p=0.8)
expected_number_of_outcomes = 20


rolls_counter = collections.Counter()

for roll in rolls:
  try:
    roll_num = int(roll.strip())
    # Let's label invalid numbers as -1
    roll_num = roll_num if 1 <= roll_num <= 20 else -1
  except ValueError:
    # Let's just label invalid generation as a roll of -1.
    if (number_map.get(roll.lower().strip())):
        roll_num = number_map.get(roll.lower().strip());
    else:
        roll_num = -1
  rolls_counter[roll_num] += 1

print(rolls_counter)
print("Percentage of valid outcomes generated:",
      (len(rolls_counter)-1)/expected_number_of_outcomes)


set(rolls)


for roll in rolls:
    print(roll)


def get_valid_counter(counter):
    # Define the value to remove
    value_to_remove = -1

    # Get the frequency of the value to remove
    frequency_to_remove = counter[value_to_remove]

    # Remove the value from the Counter
    counter.subtract({value_to_remove: frequency_to_remove})

    # Remove any negative counts (optional)
    for key in list(counter):
        if counter[key] <= 0:
            del counter[key]

    return(counter)


# unique_tokens, counts = np.unique(rolls, return_counts=True)
valid_counter = get_valid_counter(rolls_counter)
valid_num, counts = zip(*valid_counter.items())

# str_num = [str(num) for num in valid_num]

plt.bar(valid_num, counts)
plt.xlabel('valid_num')
plt.ylabel('Counts')
plt.title('Distribution of the valid responses')
plt.xticks(rotation=45)
plt.xticks(range(1, 22))
plt.show()


# try random generation
import random

rand_counter = collections.Counter()

for i in range(40):
    rand = random.randint(1, 20)
    rand_counter[rand] += 1
    # print(i)

print(rand_counter)
print("Percentage of valid outcomes generated:",
      (len(rand_counter)-1)/expected_number_of_outcomes)


num, counts = zip(*rand_counter.items())

# str_num = [str(num) for num in valid_num]

plt.bar(num, counts)
plt.xlabel('Number')
plt.ylabel('Counts')
plt.title('Distribution of the Number frequency')
plt.xticks(rotation=45)
plt.xticks(range(min(valid_num), 22))
plt.show()





import math

def calculate_ttr(text):
    words = text.split()
    unique_words = set(words)
    ttr = len(unique_words) / len(words)
    return ttr

def calculate_malones_measure(text):
    words = text.split()
    unique_words = set(words)
    d = 1 - (len(unique_words) / len(words))
    return d

def calculate_herdans_c(text):
    words = text.split()
    unique_words = set(words)
    vocabulary_size = len(unique_words)
    n = len(words)
    c = vocabulary_size / math.sqrt(n)
    return c


def output_res(res, top_p, frequency_penalty):
    print(f'Response: {res}\n')
    print(f'top_p = {top_p}')
    print(f'frequency_penalty = {frequency_penalty}')
    print(f'TTR: {calculate_ttr(res)}')
    # print(f'Malone\'s Measure: {calculate_malones_measure(res)}')
    # print(f'Herdan\'s C: {calculate_herdans_c(res)}')





# Prompt with top_p = 0.0
prompt = "Once upon a time, there is a scientist wanting to create a time machine"
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=0.0)

output_res(res, 0.0)


# Prompt with top_p = 0.5
prompt = "Once upon a time, there is a scientist wanting to create a time machine"
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.5, frequency_penalty=0.0)
output_res(res, 0.5)


# Prompt with top_p = 1.0
prompt = "Once upon a time, there is a scientist wanting to create a time machine"
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=1.0, frequency_penalty=0.0)
output_res(res, 1.0)





# prompt = "It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness,"
# Prompt with top_p = 0.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=0.0)
output_res(res, 0.0)


# Prompt with top_p = 0.5
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.5, frequency_penalty=0.0)
output_res(res, 0.5)


# Prompt with top_p = 1.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=1.0, frequency_penalty=0.0)
output_res(res, 1.0)


# Prompt with top_p = 0.0, frequency_penalty = 0.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=0.0)
output_res(res, 1.0)


# Prompt with top_p = 0.0, frequency_penalty = 0.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=0.0)
output_res(res, 0.0, 0.0)


# Prompt with top_p = 0.0, frequency_penalty = 1.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=1.0)
output_res(res, 0.0, 1.0)


# Prompt with top_p = 0.0, frequency_penalty = 2.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=2.0)
output_res(res, 0.0, 2.0)


# Prompt with top_p = 0.0, frequency_penalty = -1.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=-1.0)
output_res(res, 0.0, -1.0)


# Prompt with top_p = 0.0, frequency_penalty = 2.0
prompt = "I have a dream that one day this nation will rise up and live out the true meaning of its creed. We hold these truths to be self-evident that all men are created equal."
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.0, frequency_penalty=-2.0)
output_res(res, 0.0, -2.0)





MODEL_NAME = "davinci"
engine = OpenAIEngine(MODEL_NAME)


poem = """
No longer mourn for me when I am dead
Then you shall hear the surly sullen bell
Give warning to the world that I am fled
From this vile world, with vilest worms to dwell:
Nay, if you read this line, remember not
The hand that writ it; for I love you so
That I in your sweet thoughts would be forgot
If thinking on me then should make you woe.

O, if, I say, you look upon this verse
When I perhaps compounded am with clay,
Do not so much as my poor name rehearse.

But let your love even with my life decay,
Lest the wise world should look into your moan
And mock you with me after I am gone
"""

engine.perplexity(poem)


# with typos
poem = """
No longer mourn for me wwen I am dead
Then you shall hear the surly sulln bell
Give warning to the world that I am feed
From this vile world, with vilet worms to dwell:
Nay, if you reads this line, remember not
The hand that write it; for I love you so
That I in your sweet thoughts would be forget
If thinkink on me then should make you woe.

O, if, I say, you look upon this vese
When I perhaps componded am with clay,
Do not so much as my por name rehearse.

But let your love even wih my life decay,
Lest the wise world sould look into your moan
And mock you with me ater I am gone
"""

engine.perplexity(poem)


# Switch orders with one line
poem = """
No longer mourn for me when I am dead
Then you shall hear the surly sullen bell
Give warning to the world that I am fled
From this vile world, with vilest worms to dwell:
The hand that writ it; for I love you so
Nay, if you read this line, remember not
That I in your sweet thoughts would be forgot
If thinking on me then should make you woe.

O, if, I say, you look upon this verse
When I perhaps compounded am with clay,
Do not so much as my poor name rehearse.

But let your love even with my life decay,
Lest the wise world should look into your moan
And mock you with me after I am gone
"""

engine.perplexity(poem)


# Switch orders
poem = """
Then you shall hear the surly sullen bell
Give warning to the world that I am fled
No longer mourn for me when I am dead
Nay, if you read this line, remember not
From this vile world, with vilest worms to dwell:
The hand that writ it; for I love you so
If thinking on me then should make you woe.
That I in your sweet thoughts would be forgot


O, if, I say, you look upon this verse
Do not so much as my poor name rehearse.
When I perhaps compounded am with clay,

But let your love even with my life decay,
And mock you with me after I am gone
Lest the wise world should look into your moan
"""

engine.perplexity(poem)


# mimic poem
poem = """
O Homework! My Homework! I fear you must be done,

So many books, it pains my back, to carry every one.

Day end draws near, the bells I hear, soon I should be starting,

Quite unwise comes my defense, with teachers all to uncaring;

But O snap! snap! snap!

O the breaking of pencil lead,

Where on the floor my homework has caused me,

To have fallen cold and dead.


O Homework! My Homework! rise up and face the flag,

I pledge allegiance to only him, who never carried a school bag.

For you no more homework-eating dogs, or other lame excuse,

From where I lie, book thieving spies, are no longer of any use,

Here homework! My dear torturer,

Mark my last words said,

Never will I take another test,

For I have fallen, cold and dead.


The slamming sound of locker doors, this hall becomes my tomb,

The year is done, the kids escape, I alone am doomed.

No summer sun shall warm my heart, or make the memory fade,

Vacation cannot undo the wrong, that all the homework made,

Out the doors, to ringing bells,

As the lone janitor finds my lifeless head,

Propped up against a pile of books,

Where I have fallen, cold and dead.
"""

engine.perplexity(poem)


# new poem
poem="""
In this unveiling: a rain-stabbed
blackbird’s obsidian sigh rises

from meat-fragrant slits
in our speech patterns,

where a way of seeing home,
smeared on walls with elbow blood,

is also a way of nozzling
bird caw to thieved land,

or scissoring fog-lobed night
into crescent moons,

while a bell’s deoxygenated moan,
weeping for its lost reflection,

is hauled away on a horse-drawn hearse.
"""

engine.perplexity(poem)








# MODEL_NAME = "text-davinci-001"
MODEL_NAME="ada"
engine = OpenAIEngine(MODEL_NAME)


# copa_dataset = datasets.load_dataset("super_glue", "copa")

# # You may draw on these examples to produce few-shot prompts.
# train_data = copa_dataset["train"].shuffle(seed=1).select(range(50))

# # Use this development set to try out different few-shot prompts to see
# # what works best.
# dev_data = copa_dataset["train"].shuffle(seed=1).select(range(50, 150))

# # You should only use this at the end during final evaluation to generate
# # accuracies to put in your report.
# test_data = copa_dataset["validation"].shuffle(seed=1).select(range(100))

print("Some examples from the train set:")
for i in range(15):
  print(json.dumps(train_data[i], indent=2))


# prompt = "Given the following premise and cause, label whether the cause seems correct\n\n"
prompt = """Given the following premise and cause, label whether the cause seems correct\n Here is an example:\n PREMISE: "The woman spotted her friend from across the room.",\n Choice 1: "The woman waved.",\n Choice 2: "The woman escaped.\n Correct answer: Choice 1. \n\n"""
# eval_template = "Review: {review}\nSentiment: {sentiment}"


def classify_baseline(premise: str, choice1: str, choice2:str, type:str) -> str:
  """ Given a review, returns a sentiment prediction, 0 for negative, 1 for positive."""

  # eval_template = """Which of the following makes more sense?

  # Choice 1: {premise} This happened because: {choice1}
  # Choice 2: {premise} This happened because: {choice2}

  # {label} makes more sense.
  # """

  eval_template = """Given the premise, which of the following option is likely the {type} of the premise
  PREMISE: {premise}
  Choice 1: {choice1}
  Choice 2: {choice2}

  {label} is more likely.
  """
  label_map = {0: "Choice 1", 1: "Choice 2"}

  label_to_score = {}
  for label, label_str in label_map.items():
    label_prompt = prompt + eval_template.format(
        premise=premise, choice1=choice1, choice2=choice2, label=label_str, type=type)
    _, score = engine.score(label_prompt)
    llm_score_for_label = np.mean(score)

    label_to_score[label] = llm_score_for_label

  return max(label_to_score, key=label_to_score.get)


def evaluate(dataset, verbose: bool=False) -> float:
  """ Evaluate your prompt on the test set """
  correct = []
  for i, instance in enumerate(dataset):
    label = instance["label"]
    predicted = classify_baseline(
        instance["premise"], instance["choice1"], instance["choice2"], instance["question"])
    correct.append(1 if label == predicted else 0)

    if verbose:
      print(f"======== {i+1} / {len(dataset)} ========")
      print(f"PREMISE: {instance['premise']}")
      print(f"CHOICE 1 {'✅' if not label else '❌'}: {instance['choice1']}")
      print(f"CHOICE 2 {'✅' if label else '❌'}: {instance['choice2']}")
      print(f"PREDICTED: {'choice 2' if predicted else 'choice 1'}")
      print("type: " + instance["question"])

  acc = sum(correct) / len(correct)
  return acc

#  Once you have chosen your prompts, for final evaluation, replace dev_data
# with test_data.
# acc = evaluate(dev_data, verbose=True)
# print(f"Accuracy of your prompt on {len(test_data)} test examples: {acc:.0%}")


# prompt = "Given the following premise and cause, label whether the cause seems correct\n\n"
prompt = """You are going to do a classification task to choose a most likely option based on the give premise\n 
Here are few examples:\n 
1. PREMISE: "The woman spotted her friend from across the room.",\n 
Choice 1: "The woman waved.",\n 
Choice 2: "The woman escaped.\n 
Correct answer: Choice 1 is more likely the cause of the premise\n\n 

2. PREMISE: "The woman hired a lawyer.",\n 
Choice 1: "She decided to sue her employer.",\n 
Choice 2: "She decided to run for office."\n 
Correct answer: Choice 1 is more likely the cause of the premise.\n\n 

3. PREMISE: "The girl made a wish.",\n 
Choice 1: "She saw a black cat.",\n Choice 2: "She saw a shooting star."\n 
Correct answer: Choice 2 is more likely the cause of the premise.\n\n"""
acc = evaluate(test_data, verbose=True)
print(f"Accuracy of your prompt on {len(test_data)} test examples: {acc:.0%}")


# Error analysis:
acc


# prompt = "Given the following premise and cause, label whether the cause seems correct\n\n"
prompt = """You are going to do a classification task to choose a most likely option based on the give premise\n 
Here are few examples:\n
1. PREMISE: "The homeowners disliked their nosy neighbors.",\n 
Choice 1: "He went away to camp.",\n 
Choice 2: "He bickered with his sister."\n 
Correct answer: Choice 1 is more likely the cause of the premise.\n\n

2. PREMISE: "The woman hired a lawyer.",\n 
Choice 1: "She decided to sue her employer.",\n 
Choice 2: "She decided to run for office."\n 
Correct answer: Choice 1 is more likely the cause of the premise.\n\n 

3. PREMISE: "The girl made a wish.",\n 
Choice 1: "She saw a black cat.",\n Choice 2: "She saw a shooting star."\n 
Correct answer: Choice 2 is more likely the cause of the premise.\n\n 

4. PREMISE: "The woman spotted her friend from across the room.",\n 
Choice 1: "The woman waved.",\n 
Choice 2: "The woman escaped.\n 
Correct answer: Choice 1 is more likely the cause of the premise\n\n 

5. PREMISE: "The woman tolerated her friend's difficult behavior.",\n 
Choice 1: "The woman knew her friend was going through a hard time.",\n 
Choice 2: "The woman felt that her friend took advantage of her kindness."\n 
Correct answer: Choice 2 is more likely the cause of the premise.\n\n 
"""
acc = evaluate(test_data, verbose=True)
print(f"Accuracy of your prompt on {len(test_data)} test examples: {acc:.0%}")


acc = evaluate(test_data, verbose=True)
print(f"Accuracy of your prompt on {len(test_data)} test examples: {acc:.0%}")


prompt = """
I want you to perform a text generation task. When I give you a sentence, could you try to add a space between each character? \n
Here is some examples:\n\n
Sentence: hey, how are you. \t 
Response: h e y , h o w a r e y o u . \n

Sentence: Good Morning. \t 
Response: G o o d M o r n i n g . \n

Sentence: I Love LLM. \t 
Response: I L o v e L L M . \n

Now, convert this sentence for me: Few-shot learning techniques can also be used for tasks that require generation.
"""
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.5, frequency_penalty=0.0)


print(res)


prompt = """
Given the English sentences, convert them into Pig Latin. Here are some examples to guide you:

English: "hello"
Pig Latin: "ellohay"

English: "world"
Pig Latin: "orldway"

English: "OpenAI"
Pig Latin: "OpenAIway"

Now, convert the following sentence into Pig Latin:

English: "language models are fascinating"
"""
res = engine.generate(prompt, num_tokens=256, num_samples=1, top_p=0.5, frequency_penalty=0.0)








# MODEL_NAME = "davinci"
MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)


prompt = "I want to write a short introduction of Kobe Bryant, help me to comleted the introduction and give me facts in the introductions: Kobe Bean Bryant (/ˈkoʊbi/ KOH-bee; August 23, 1978 – January 26, 2020) was an American professional basketball player. A shooting guard, he spent his entire 20-year career with the Los Angeles Lakers in the National Basketball Association (NBA)"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "davinci"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "I want to write a short introduction of Kobe Bryant, help me to comleted the introduction and give me facts in the introductions: Kobe Bean Bryant (/ˈkoʊbi/ KOH-bee; August 23, 1978 – January 26, 2020) was an American professional basketball player. A shooting guard, he spent his entire 20-year career with the Los Angeles Lakers in the National Basketball Association (NBA)"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "davinci"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "Elon Musk is one of the greatest basketball players in the world and he is currently plaing for the Pittsburgh Pirate,"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "ada"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "Elon Musk is one of the greatest basketball players in the world and he is currently plaing for the Pittsburgh Pirate,"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)





MODEL_NAME = "davinci"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "I want to cook Spaghetti with Meat Sauce, the recipe for this dish is"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "text-davinci-003"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "I want to cook Spaghetti with Meat Sauce, the recipe for this dish is"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "davinci"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "I am learning to play basketball, the rule for the game of basketball is"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "text-davinci-003"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "I am learning to play basketball, the rule for the game of basketball is"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "davinci"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "Kobe Bean Bryant (/ˈkoʊbi/ KOH-bee; August 23, 1978 – January 26, 2020) was an American professional basketball player. A shooting guard, he spent his entire 20-year career with the Los Angeles Lakers in the National Basketball Association (NBA)"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)


MODEL_NAME = "text-davinci-003"
# MODEL_NAME = "ada"
engine = OpenAIEngine(MODEL_NAME)
prompt = "Kobe Bean Bryant (/ˈkoʊbi/ KOH-bee; August 23, 1978 – January 26, 2020) was an American professional basketball player. A shooting guard, he spent his entire 20-year career with the Los Angeles Lakers in the National Basketball Association (NBA)"
res = engine.generate(prompt, num_tokens=300, num_samples=1, top_p=0.5, frequency_penalty=0.0)
print(res)



